{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f24a12-ddf9-4244-b1ad-35e0f896c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu사용\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # True면 GPU 사용 가능!\n",
    "print(torch.cuda.get_device_name(0))  # GPU 이름 출력\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.tensor([1.0, 2.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63395eab-3a86-4ba2-9ade-0754891e6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # 명시적으로 인자명을 써주는 경우도 많이 쓰인다고 한다.\n",
    "        self.linear = nn.Linear(in_features = input_dim, out_features = output_dim)\n",
    "        self.activation = nn.ReLU() # 시그모이드 함수\n",
    "        # self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear(x)) # 리니어 통과 후 활성화 통"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b218765-9acd-49aa-99af-2f253ea04a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4) # input\n",
    "y = torch.zeros(3) # out\n",
    "model = LinearRegressionModel(4,3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba50662-0500-41ac-a206-4d8c81ddfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f70bf84-8706-436a-8557-71414abbf74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0442, -0.4486,  0.1079, -0.1035],\n",
      "        [ 0.0588,  0.2621, -0.4610, -0.0590],\n",
      "        [ 0.1966,  0.0600,  0.1223, -0.0958]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4836,  0.0704, -0.4542], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss) # sigmoid에 비해 relu가 엄청나게 오차를 줄인다. \n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11d089-8b82-4fd7-997c-0ec47cd9a26b",
   "metadata": {},
   "source": [
    "## 다층 레이어 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920601b4-60a8-45a6-8b9b-f4f381560b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 10)\n",
    "        self.linear2 = nn.Linear(10, 10)\n",
    "        self.linear3 = nn.Linear(10, 10)\n",
    "        self.linear4 = nn.Linear(10, output_dim)\n",
    "        self.activation = nn.LeakyReLU(0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #|x| = (input_dim, output_dim)\n",
    "        hidden = self.activation(self.linear1(x))\n",
    "        hidden = self.activation(self.linear2(hidden))\n",
    "        hidden = self.activation(self.linear3(hidden))\n",
    "        y = self.linear4(hidden) # 마지막 출력에는 activation 함수를 사용하지 않는 것이 일반적\n",
    "        return y # 가시성을 위해 분리해서 쓰는겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0d248d-313e-4e08-b8b0-eab9ab073885",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "model = LinearRegressionModel(4, 3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b8a17c-6d53-4802-8cd3-08bb0d53833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d3e9225-8372-47d5-861d-d834ed4718e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1288e-09, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.2797, -0.1138,  0.3802, -0.0796],\n",
      "        [-0.3490, -0.4342,  0.2225, -0.2356],\n",
      "        [-0.4482,  0.1348, -0.0949, -0.1305],\n",
      "        [-0.1516, -0.1979,  0.2130,  0.1586],\n",
      "        [-0.0760,  0.3355, -0.2252, -0.3781],\n",
      "        [ 0.2506,  0.3882,  0.2106,  0.3340],\n",
      "        [ 0.4139,  0.4783, -0.4661,  0.3483],\n",
      "        [-0.2251,  0.3306,  0.4859,  0.3596],\n",
      "        [-0.4595, -0.1920,  0.0952,  0.4251],\n",
      "        [-0.2760, -0.2601,  0.2324, -0.4446]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2905,  0.2244, -0.0686,  0.3783,  0.3194,  0.4856, -0.4331, -0.2762,\n",
      "        -0.4506,  0.4404], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1812,  0.1498, -0.2104, -0.3030,  0.1367, -0.0837, -0.2702,  0.0624,\n",
      "          0.2621, -0.2911],\n",
      "        [ 0.1741, -0.0866, -0.2045, -0.0576, -0.1272, -0.0456,  0.2864, -0.2122,\n",
      "         -0.1366,  0.0176],\n",
      "        [-0.2956,  0.1266,  0.2424,  0.2591, -0.1698, -0.1345,  0.2788, -0.0497,\n",
      "          0.0413,  0.2718],\n",
      "        [ 0.0818, -0.0173, -0.2440, -0.0674, -0.1260,  0.0871, -0.2732,  0.1436,\n",
      "          0.0791,  0.0471],\n",
      "        [ 0.0090, -0.3076, -0.2480, -0.0456,  0.1631,  0.0576, -0.1297,  0.1578,\n",
      "          0.0363, -0.1432],\n",
      "        [-0.2321,  0.2082,  0.2177, -0.1352,  0.1751,  0.2294,  0.2159, -0.1267,\n",
      "          0.2030, -0.1452],\n",
      "        [-0.1507, -0.2779, -0.2628, -0.1037,  0.1428,  0.2724, -0.0280, -0.2980,\n",
      "         -0.2987, -0.0541],\n",
      "        [-0.1484,  0.1029, -0.1212,  0.1749, -0.2518,  0.2360,  0.1622,  0.2551,\n",
      "          0.2889, -0.0533],\n",
      "        [-0.0901, -0.0807, -0.1300, -0.1225,  0.0300, -0.2510, -0.0810,  0.1811,\n",
      "         -0.2319,  0.1100],\n",
      "        [-0.1147,  0.0667,  0.2806, -0.2675,  0.0610, -0.1576,  0.2929, -0.0980,\n",
      "          0.1475, -0.0910]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0497,  0.2775,  0.2202, -0.1217,  0.2275, -0.2333,  0.0955, -0.3036,\n",
      "         0.0196, -0.0120], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2678, -0.0551,  0.0262, -0.0355, -0.0576,  0.0301, -0.2014, -0.2520,\n",
      "          0.2348,  0.2628],\n",
      "        [ 0.2199,  0.1844,  0.1487, -0.2821,  0.0585,  0.2529, -0.2986, -0.0055,\n",
      "          0.2349, -0.2152],\n",
      "        [-0.1093,  0.2923,  0.2955,  0.2701,  0.0664, -0.1081, -0.2668, -0.0250,\n",
      "          0.0018, -0.1861],\n",
      "        [-0.1798,  0.1386,  0.1014,  0.0936, -0.0360, -0.0484, -0.2849, -0.0434,\n",
      "         -0.2619, -0.2095],\n",
      "        [-0.1761,  0.2180, -0.0431,  0.0874,  0.1091,  0.1470,  0.1553,  0.1317,\n",
      "          0.2199,  0.1718],\n",
      "        [-0.2425, -0.2690,  0.1505,  0.2048, -0.2926,  0.0767, -0.1371,  0.1283,\n",
      "         -0.2837,  0.0363],\n",
      "        [-0.1517, -0.3042, -0.1734, -0.1936,  0.1286, -0.0933, -0.0059, -0.0043,\n",
      "         -0.0270,  0.1924],\n",
      "        [ 0.0127,  0.2671, -0.0117, -0.1411,  0.1511, -0.1834,  0.1427,  0.0502,\n",
      "          0.1691, -0.1255],\n",
      "        [ 0.2133, -0.3102,  0.1189, -0.1658,  0.0190, -0.2010,  0.1335,  0.0238,\n",
      "          0.0615, -0.0855],\n",
      "        [ 0.1096, -0.1603,  0.0611, -0.0403, -0.1753,  0.1535,  0.3060, -0.1544,\n",
      "          0.2668,  0.1892]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1781, -0.0969,  0.0318,  0.1674,  0.0831,  0.2384, -0.1695, -0.1304,\n",
      "        -0.2858, -0.0287], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2139,  0.2169,  0.1102, -0.2745,  0.2560, -0.1070,  0.2602, -0.2323,\n",
      "          0.1374,  0.1284],\n",
      "        [-0.1490,  0.2501,  0.1166, -0.1207,  0.2191, -0.1525,  0.1333, -0.1162,\n",
      "         -0.2491, -0.3066],\n",
      "        [-0.2183, -0.2887, -0.1110, -0.1845,  0.0789,  0.2036,  0.0095,  0.0844,\n",
      "          0.2520,  0.2506]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0317, -0.0297, -0.0277], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss) # sigmoid에 비해 relu가 엄청나게 오차를 줄인다. \n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07085b-a671-4631-9a6f-fdeece36f2e5",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdc6a82-6c30-4ac2-8f4b-86442bac1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이거 이용하면 더 쉽게 사용 가능하다\n",
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "input_dim = x.size(0)\n",
    "output_dim = y.size(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 10),\n",
    "    nn.LeakyReLU(0, 1),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.LeakyReLU(0, 1),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.LeakyReLU(0, 1),\n",
    "    nn.Linear(10, output_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf2d9974-9971-4bd2-9bec-bb150d24f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302808eb-193b-42d3-9f50-da69cb575701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    y_pred = model(x)\n",
    "    loss = loss_function(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e6cb55-c241-4f9a-9fc5-68e8c1c27685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.6500e-10, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.4482, -0.3585, -0.1033,  0.1997],\n",
      "        [ 0.4611, -0.4423,  0.1648,  0.2349],\n",
      "        [-0.2190,  0.2594,  0.4981, -0.0503],\n",
      "        [-0.2283,  0.1484, -0.3257, -0.1747],\n",
      "        [ 0.3029, -0.1750,  0.2513,  0.1611],\n",
      "        [-0.2855,  0.2584, -0.4564,  0.2334],\n",
      "        [-0.4482, -0.4303,  0.1178, -0.0039],\n",
      "        [ 0.2350,  0.1737, -0.3141, -0.3255],\n",
      "        [-0.3692, -0.4436,  0.1716,  0.3662],\n",
      "        [ 0.0715, -0.1749, -0.0785, -0.1780]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1899, -0.1265,  0.3498, -0.0259,  0.0619,  0.1063, -0.1283, -0.2750,\n",
      "        -0.3074,  0.3633], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.0052e-01,  2.4639e-01,  1.3499e-01, -2.2844e-01,  2.1062e-01,\n",
      "          1.5670e-01,  4.8534e-02,  1.8237e-01, -2.9702e-01,  9.8999e-02],\n",
      "        [ 1.3333e-01,  2.8756e-01, -4.2289e-02, -2.8050e-01, -4.3295e-03,\n",
      "         -2.8505e-01, -1.3696e-01, -1.0937e-05, -1.1120e-01, -2.5357e-01],\n",
      "        [ 1.7723e-01, -9.6481e-02,  8.2042e-02,  4.4725e-02, -1.4222e-01,\n",
      "         -2.2211e-02, -2.2029e-01,  3.0803e-01, -2.1335e-01, -1.5934e-01],\n",
      "        [-2.0545e-01,  3.3709e-02,  1.0294e-01, -2.5545e-02, -2.9406e-01,\n",
      "          1.7757e-01, -1.5142e-01, -2.7891e-01, -3.4515e-02,  1.5609e-01],\n",
      "        [ 1.6748e-01, -1.3800e-02,  1.6717e-02,  8.3436e-02, -3.4154e-02,\n",
      "          1.3391e-01, -2.0480e-02,  4.2451e-02, -2.4001e-01, -1.9954e-01],\n",
      "        [ 2.6863e-01,  1.8462e-01,  1.9554e-01, -2.5926e-01, -3.1461e-01,\n",
      "          7.6728e-02,  2.4256e-01,  1.1729e-01,  1.6977e-01, -1.5281e-01],\n",
      "        [ 2.4231e-01, -3.0311e-01, -2.9859e-02, -1.2596e-01, -1.3163e-01,\n",
      "          2.0530e-01, -6.2324e-02, -1.2827e-01,  2.1637e-01,  1.7470e-01],\n",
      "        [ 1.1608e-01, -1.5426e-01, -2.8368e-01, -2.7410e-01,  8.8669e-02,\n",
      "         -3.0565e-01,  2.1003e-01, -2.1273e-01, -3.1376e-01, -7.5092e-02],\n",
      "        [-1.2653e-01, -2.5062e-01, -1.2536e-01, -1.6647e-01, -6.2611e-02,\n",
      "         -2.6050e-01,  7.6311e-02,  8.3279e-02, -2.4710e-01, -2.5490e-01],\n",
      "        [-2.5013e-01, -2.0685e-01, -3.9728e-02, -2.4359e-01,  7.0440e-02,\n",
      "         -2.5976e-01,  2.2505e-02, -1.1651e-01, -2.8918e-01,  1.5164e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2011,  0.1802, -0.2939, -0.0711,  0.2573, -0.0707, -0.2265, -0.0520,\n",
      "         0.0806, -0.0689], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0297,  0.0613,  0.0519,  0.1856, -0.2845,  0.2711,  0.1808, -0.1150,\n",
      "         -0.2912,  0.0730],\n",
      "        [ 0.0234, -0.0753, -0.3045,  0.1983, -0.1844, -0.1741,  0.1094, -0.0512,\n",
      "          0.1944, -0.2336],\n",
      "        [ 0.1338, -0.1022, -0.2036, -0.1039,  0.2256, -0.1335, -0.0482, -0.0194,\n",
      "         -0.1210, -0.1901],\n",
      "        [-0.2557, -0.2078, -0.0839,  0.2841, -0.0664, -0.1222, -0.1948,  0.3090,\n",
      "          0.1642,  0.1218],\n",
      "        [-0.0944, -0.0051,  0.2922,  0.1525, -0.2872, -0.1965, -0.2002, -0.1743,\n",
      "          0.1030,  0.2236],\n",
      "        [ 0.0147,  0.1806, -0.0759, -0.1691,  0.1764, -0.0539, -0.1959,  0.1871,\n",
      "          0.1630,  0.3001],\n",
      "        [-0.2299,  0.3092, -0.2808,  0.1639,  0.2978,  0.0552, -0.0671,  0.0592,\n",
      "          0.2546,  0.2290],\n",
      "        [-0.1614,  0.2518,  0.0130,  0.0466,  0.2697,  0.1002, -0.0479,  0.2698,\n",
      "         -0.2523, -0.0220],\n",
      "        [ 0.0876,  0.2622,  0.2688,  0.0180, -0.1329, -0.1619, -0.2426, -0.1055,\n",
      "         -0.3137,  0.1350],\n",
      "        [ 0.2459, -0.1615, -0.2335,  0.1434, -0.3105, -0.1792, -0.1990,  0.0972,\n",
      "          0.2890, -0.3049]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0230, -0.1573,  0.0072, -0.2059,  0.1201,  0.0387,  0.2301,  0.2587,\n",
      "        -0.1562, -0.2224], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1331,  0.0203,  0.0140, -0.1577,  0.1542, -0.0864, -0.0587,  0.0299,\n",
      "          0.2993, -0.0166],\n",
      "        [-0.0685,  0.0634, -0.2652, -0.2073, -0.2946, -0.0087, -0.2292, -0.1614,\n",
      "          0.1194,  0.0536],\n",
      "        [-0.1564, -0.1984, -0.3008, -0.2779, -0.2575,  0.0493, -0.1846,  0.0673,\n",
      "         -0.2277, -0.1501]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0158, 0.1366, 0.0531], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c78f50d-566d-46bc-86c5-27e22562f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD 방식 구현\n",
    "# 랜덤하게 데이터를 섞기 위한 함수\n",
    "# torch.randperm(n): 0 ~ n-1 까지의 정수를 랜덤하게 섞어서 순열(배열)을 만들어 준다.\n",
    "# torch.index_select(텐서객체, 차원번호, 인덱스텐서), 차원번호 = axis를 의미\n",
    "# 특정 차원의 나열된 인덱스 번호 순서대로 데이터를 섞어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcde8dba-1222-49df-80ab-fbfaac79658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1511, -0.5594,  0.2022,  1.9242],\n",
      "        [ 1.1306,  0.6468, -0.5747,  1.7867],\n",
      "        [-0.3386,  0.2676, -0.1767, -0.6475]])\n",
      "tensor([1, 2])\n",
      "tensor([[ 1.1306,  0.6468, -0.5747,  1.7867],\n",
      "        [-0.3386,  0.2676, -0.1767, -0.6475]])\n",
      "tensor([[-0.5594,  0.2022],\n",
      "        [ 0.6468, -0.5747],\n",
      "        [ 0.2676, -0.1767]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "data1 = torch.randn(3,4)\n",
    "print(data1)\n",
    "indices = torch.tensor([1,2])\n",
    "print(indices)\n",
    "print(torch.index_select(data1, 0, indices))\n",
    "print(torch.index_select(data1, 1, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1afc3a0-c101-48f7-8b9c-0d8aeea06190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 구현\n",
    "x = torch.ones(5000, 10).to(device)\n",
    "y = torch.zeros(5000, 1).to(device)\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "minibatch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f4a8d9f-c51b-401e-b9c3-e4b5f8ac5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.size(-1)\n",
    "output_dim = y.size(-1)\n",
    "\n",
    "# 보통 히든레이어는 출력에 가까울 수록 작아지게 설계하는 것이 일반적 => 성능이 좋아짐\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 10),\n",
    "    nn.LeakyReLU(0, 1),\n",
    "    nn.Linear(10,8),\n",
    "    nn.LeakyReLU(0, 1),\n",
    "    nn.Linear(8,6),\n",
    "    nn.LeakyReLU(0, 1),\n",
    "    nn.Linear(6, output_dim)\n",
    ").to(device)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10f642f6-54a5-4899-a066-94ebf134f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2766,  503,  707,  ..., 2367, 1627, 2916], device='cuda:0')\n",
      "20 20\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(x.size(0), device = device) # 섞어주는 역할을 한다.\n",
    "print(indices)\n",
    "x_batch_list = torch.index_select(x, 0, index=indices)\n",
    "y_batch_list = torch.index_select(y, 0, index=indices)\n",
    "\n",
    "x_batch_list = x_batch_list.split(minibatch_size, dim = 0)\n",
    "y_batch_list = y_batch_list.split(minibatch_size, dim = 0)\n",
    "print(len(x_batch_list), len(y_batch_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5de8a7c-6958-40c3-a268-9248456ef45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.6736e-15, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.1305, -0.1369,  0.0398, -0.0706,  0.2254, -0.0169, -0.3097, -0.2033,\n",
      "          0.0706,  0.0916],\n",
      "        [ 0.0955, -0.1266,  0.1437,  0.2260, -0.0416,  0.2009,  0.2622, -0.1392,\n",
      "          0.0106,  0.2474],\n",
      "        [-0.0610, -0.1722,  0.2486,  0.2016, -0.0188,  0.2550, -0.1352, -0.0380,\n",
      "          0.1016,  0.1776],\n",
      "        [ 0.1927,  0.1325,  0.1567, -0.2462,  0.2293, -0.0229,  0.1546,  0.2015,\n",
      "         -0.1022, -0.2912],\n",
      "        [ 0.0740,  0.1997, -0.1856,  0.2691,  0.0416,  0.0753, -0.0446, -0.2937,\n",
      "          0.2463,  0.1638],\n",
      "        [ 0.2751,  0.2136,  0.2546,  0.1048,  0.1698,  0.1316, -0.2045,  0.1996,\n",
      "          0.1780, -0.1922],\n",
      "        [ 0.1074, -0.0976, -0.0408, -0.1969,  0.3005, -0.0718,  0.2840, -0.2194,\n",
      "          0.1256,  0.1147],\n",
      "        [ 0.2191, -0.0606,  0.0261, -0.2185,  0.2693, -0.1868,  0.0330,  0.1075,\n",
      "         -0.0313, -0.0686],\n",
      "        [-0.1162, -0.0597, -0.1418,  0.1911, -0.1590,  0.0146, -0.2556, -0.0669,\n",
      "         -0.1997,  0.2403],\n",
      "        [ 0.2655, -0.1379, -0.2428,  0.0806,  0.1064,  0.1640, -0.1716, -0.1330,\n",
      "          0.0797,  0.0051]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2812, -0.0636, -0.1189, -0.0989,  0.0306,  0.1710,  0.2957, -0.2310,\n",
      "         0.2534, -0.1427], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1492, -0.3060,  0.0716, -0.1680, -0.0507,  0.2984, -0.3061,  0.1411,\n",
      "         -0.2268,  0.0695],\n",
      "        [-0.1611, -0.0412,  0.2658,  0.2729, -0.3014, -0.2281,  0.1038, -0.1085,\n",
      "          0.2839,  0.2018],\n",
      "        [ 0.2816,  0.0265, -0.1357, -0.3104, -0.1811,  0.1067, -0.0152,  0.1826,\n",
      "         -0.2200,  0.3009],\n",
      "        [-0.2569, -0.1472,  0.0212, -0.0126,  0.2859,  0.1108, -0.0705, -0.0272,\n",
      "          0.1825, -0.1199],\n",
      "        [-0.0568, -0.0727, -0.1883,  0.2801,  0.1368,  0.0544,  0.0227,  0.2003,\n",
      "         -0.0879,  0.3060],\n",
      "        [ 0.1824, -0.0675, -0.1862,  0.2918,  0.1216,  0.1047,  0.1908,  0.2527,\n",
      "          0.0782, -0.2714],\n",
      "        [ 0.1721,  0.0782,  0.2597, -0.1226,  0.0990,  0.2070,  0.2991, -0.1538,\n",
      "         -0.1573, -0.1573],\n",
      "        [ 0.2340, -0.1723,  0.1711,  0.0911, -0.0109,  0.0912, -0.2329,  0.1947,\n",
      "          0.1620,  0.0203]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0648,  0.0273, -0.2713,  0.2117,  0.0068, -0.1457, -0.0120,  0.2848],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1603,  0.2256, -0.1575,  0.0653, -0.2633, -0.3361, -0.2559,  0.0248],\n",
      "        [ 0.2953, -0.2012,  0.1708,  0.1316, -0.1952,  0.1762,  0.2344,  0.2875],\n",
      "        [ 0.3236,  0.0714,  0.3527,  0.2670, -0.2355,  0.0703, -0.2845, -0.1782],\n",
      "        [ 0.3350,  0.1646, -0.0940, -0.1841, -0.2992, -0.0963,  0.1643, -0.1657],\n",
      "        [ 0.2136,  0.1521,  0.1385,  0.3471, -0.0221, -0.0896,  0.0899, -0.1075],\n",
      "        [-0.0194,  0.1256, -0.2167,  0.2125,  0.0731,  0.1648,  0.2206,  0.1022]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2758, -0.2203, -0.1192, -0.2439,  0.3039,  0.2660], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2288,  0.1036, -0.1189,  0.3189, -0.3850,  0.2393]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0409], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for index in range(nb_epochs):\n",
    "    indices = torch.randperm(x.size(0),device=device)\n",
    "\n",
    "    x_batch_list = torch.index_select(x, 0, index=indices)\n",
    "    y_batch_list = torch.index_select(y, 0, index=indices)\n",
    "    x_batch_list = x_batch_list.split(minibatch_size, 0)\n",
    "    y_batch_list = y_batch_list.split(minibatch_size, 0)\n",
    "\n",
    "    for x_minibatch, y_minibatch in zip(x_batch_list, y_batch_list):\n",
    "        y_minibatch_pred = model(x_minibatch)\n",
    "        loss = loss_function(y_minibatch_pred, y_minibatch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75920424-1622-40c2-88cf-89ed25e66346",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.tensor([1.0, 2.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "750a72b9-ec0c-485c-8ad6-3985133a8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 실험 결과와 그 대의 설정값을 관리해주는 프레임워크\n",
    "# MLFlow, WanDB 가 있다.\n",
    "\n",
    "# 주요 Optimizer\n",
    "# 딥러닝의 학습은 결국 손실값을 가장 작게 모델을 만드는 것\n",
    "# 즉, 학습은 손실함수(liss function) 최소값을 찾아가는 과정이며 이 과정을 최적화(Optimization) 이라고 한다.\n",
    "# 대표적인게 SGD임\n",
    "# 이 외에도 다양한 Optimizer가 제안되고 있다. ex) adam, momentum(sgd에 관성을 추가한거임), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa779587-b16e-4423-a87f-1532b5165d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952b297-ada9-4949-b633-7ddd9a30b6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbeffed-4121-419d-9243-a8fd228167e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
