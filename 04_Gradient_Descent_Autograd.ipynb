{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793ad972-154f-4e7b-b079-d5656ab32525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer와 경사하강법\n",
    "# 최적화는 각 학습 단계에서 모델의 오류를 줄이기 위해 모델 매개변수를 조정하는 과정으로 Optimizer는 최적화 알고리즘을 의미한다.\n",
    "# 대표적인 최적화 알고리즘이 확률적 경사하강법(SGD)\n",
    "# Pytorch 에는 모델과 데이터 타입에 따라 보다 좋은 성능을 제공하는 ADAM이나 RMSProop과 같은 다양한 옵티마이저가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9ad54b-c0a0-44b4-9e16-91ad450082ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용법\n",
    "# oprimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습단계\n",
    "# optimizer.zero_grad()를 호출하여 모델 파라미터의 미분값(변화도) 를 0 으로 초기화해준다.   = detach_().requires_grad_(True) 이거랑 같은 듯\n",
    "# loss.backward()를 호출하여 backward pass를 계산하고 연산에 연결된 각 텐서들의 미분 값을 각 텐서객체 grad에 저장한다.\n",
    "# optimizer.step()을 호출하여 역전파 단계에서 계산된 미분값(변화도) 를 기준으로 모델 파라미터 값을 업데이트 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18da84f2-04d7-49f6-8fef-23176297d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(4.)\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "w = torch.tensor(4.0, requires_grad = True)\n",
    "z = 2 * w\n",
    "z.backward()\n",
    "print(w.grad)\n",
    "\n",
    "z = 2 * w\n",
    "z.backward()\n",
    "print(w.grad)\n",
    "\n",
    "z = 2 * w\n",
    "z.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# 끊어주지 않으니 계속 chain rule 되는 것을 알 수 있음\n",
    "# 이걸 끊어 줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85c3b816-32e4-407a-8bc3-d13915c2f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "w = torch.rand(4,3, requires_grad = True)\n",
    "b = torch.rand(3, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4094f46-219b-4d77-bfb0-bd7f4a1ac48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD([w,b], lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4051591d-e972-490e-bb60-9e1f2c07b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭:  0\n",
      "nb_epochs:  300\n",
      "weight:  tensor([[0.2717, 0.6532, 0.8424],\n",
      "        [0.7917, 0.3057, 0.4152],\n",
      "        [0.6449, 0.9604, 0.0752],\n",
      "        [0.0209, 0.0227, 0.8180]], requires_grad=True)\n",
      "bias:  tensor([0.5316, 0.9110, 0.8020], requires_grad=True)\n",
      "loss:  tensor(7.8372, grad_fn=<MseLossBackward0>)\n",
      "--------------------------------------------------------------------------------\n",
      "에폭:  100\n",
      "nb_epochs:  300\n",
      "weight:  tensor([[-0.1652,  0.1018,  0.2717],\n",
      "        [ 0.3548, -0.2456, -0.1554],\n",
      "        [ 0.2080,  0.4090, -0.4955],\n",
      "        [-0.4161, -0.5287,  0.2473]], requires_grad=True)\n",
      "bias:  tensor([0.0947, 0.3596, 0.2313], requires_grad=True)\n",
      "loss:  tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "--------------------------------------------------------------------------------\n",
      "에폭:  200\n",
      "nb_epochs:  300\n",
      "weight:  tensor([[-0.1800,  0.0833,  0.2525],\n",
      "        [ 0.3401, -0.2642, -0.1747],\n",
      "        [ 0.1933,  0.3904, -0.5147],\n",
      "        [-0.4308, -0.5473,  0.2281]], requires_grad=True)\n",
      "bias:  tensor([0.0800, 0.3410, 0.2121], requires_grad=True)\n",
      "loss:  tensor(1.0113e-05, grad_fn=<MseLossBackward0>)\n",
      "--------------------------------------------------------------------------------\n",
      "에폭:  300\n",
      "nb_epochs:  300\n",
      "weight:  tensor([[-0.1805,  0.0826,  0.2519],\n",
      "        [ 0.3396, -0.2648, -0.1753],\n",
      "        [ 0.1928,  0.3898, -0.5153],\n",
      "        [-0.4313, -0.5479,  0.2275]], requires_grad=True)\n",
      "bias:  tensor([0.0795, 0.3404, 0.2115], requires_grad=True)\n",
      "loss:  tensor(1.1495e-08, grad_fn=<MseLossBackward0>)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "nb_epochs = 300\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    z = torch.matmul(x,w) + b\n",
    "    loss = F.mse_loss(z, y)\n",
    "\n",
    "    optimizer.zero_grad() # 초기화\n",
    "    loss.backward() # 편미분 계산\n",
    "    optimizer.step() # 업데이트\n",
    "\n",
    "    if epoch % 100 == 0: # 100 번마다 출력\n",
    "        print(\"에폭: \",epoch)\n",
    "        print(\"nb_epochs: \",nb_epochs)\n",
    "        print(\"weight: \",w)\n",
    "        print(\"bias: \",b)\n",
    "        print(\"loss: \",loss)\n",
    "        print(\"----------------\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537b81aa-8904-4a9b-bdb8-3d26e174790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈을 이용해서 더 간단하게 만들 수 있도록 하기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "model = LinearRegressionModel(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efc7ddea-9bba-4f36-9311-2e0668ec9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    pred = model(x)\n",
    "    loss = F.mse_loss(pred, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e1632fa-5462-45be-abeb-fd4cdc0f902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2570e-13, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0377, -0.0468,  0.1864, -0.1111],\n",
      "        [ 0.4505, -0.2300, -0.3133,  0.0983],\n",
      "        [-0.3646, -0.4818,  0.3857,  0.3771]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0663, -0.0053,  0.0837], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a42753c-07ee-45ff-b0b2-17c2b445fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabets_data = load_diabetes()\n",
    "\n",
    "diabets_data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4dd98-d810-4f9c-997a-1b7c82581e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
